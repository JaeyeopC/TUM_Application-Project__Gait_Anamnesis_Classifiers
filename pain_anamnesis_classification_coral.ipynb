{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b3024e-0cc6-4381-b0b2-c2f2c3d081d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9a8c481-0a74-4cfb-8f3f-1d009f04ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 1. Data Loading and Preprocessing\n",
    "#########################################\n",
    "\n",
    "# Load the Excel file (make sure you have openpyxl installed: pip install openpyxl)\n",
    "data = pd.read_excel(\"colored_columns_output_filtered.xlsx\")  # Replace with your file path\n",
    "\n",
    "# Define the 7 input columns.\n",
    "input_cols = [\n",
    "    \"SchiefstandBewegungMmDurchschnitt_links\",\n",
    "    \"SchiefstandBewegungMmDurchschnitt_rechts\",\n",
    "    \"SchiefstandRuheMmDurchschnitt_links\",\n",
    "    \"SchiefstandRuheMmDurchschnitt_rechts\",\n",
    "    \"AuftrittDurchschnitt_links\",\n",
    "    \"AuftrittDurchschnitt_rechts\",\n",
    "    \"Schuhgröße\"\n",
    "]\n",
    "\n",
    "# Define the target columns.\n",
    "binary_target_cols = [\n",
    "    \"Schmerz_Vorfuß_Links\", \"Schmerz_Vorfuß_Rechts\", \n",
    "    \"Schmerz_Mittelfuß_Links\", \"Schmerz_Mittelfuß_Rechts\",\n",
    "    \"Schmerz_Ferse_Links\", \"Schmerz_Ferse_Rechts\",\n",
    "    \"Schmerz_Handgelenk_links\", \"Schmerz_Handgelenk_rechts\",\t\n",
    "    \"Schmerz_Ellenbogen_links\", \"Schmerz_Ellenbogen_rechts\",\t\n",
    "    \"Schmerz_Finger_links\",\t\"Schmerz_Finger_rechts\",\t\n",
    "    \"Schmerz_Oberarm_links\", \"Schmerz_Oberarm_rechts\",\t\n",
    "    \"Schmerz_Daumen_links\",\t\"Schmerz_Daumen_rechts\",\t\n",
    "    \"Schmerz_Unterarm_links\", \"Schmerz_Unterarm_rechts\"\n",
    "]\n",
    "\n",
    "# Assume that any \"Schmerz_*\" column that is not in binary_target_cols is ordinal.\n",
    "all_schmerz_cols = [col for col in data.columns if col.startswith(\"Schmerz_\")]\n",
    "ordinal_target_cols = [col for col in all_schmerz_cols if col not in binary_target_cols]\n",
    "\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.dropna(subset=ordinal_target_cols, inplace=True)\n",
    "\n",
    "# Convert binary targets to 0/1.\n",
    "for col in binary_target_cols:\n",
    "    data[col] = data[col].map({True: 1, 'TRUE': 1, 'True': 1,\n",
    "                               False: 0, 'FALSE': 0, 'False': 0})\n",
    "\n",
    "# Ensure ordinal targets are integers.\n",
    "for col in ordinal_target_cols:\n",
    "    data[col] = data[col].astype(int)\n",
    "\n",
    "# Extract features and targets.\n",
    "X = data[input_cols].values.astype(np.float32)\n",
    "y_binary = data[binary_target_cols].values.astype(np.float32)\n",
    "y_ordinal = data[ordinal_target_cols].values.astype(np.int64)  # each column: class labels 0–5\n",
    "\n",
    "# Split the data into training and test sets (80/20 split).\n",
    "X_train, X_test, yb_train, yb_test, yo_train, yo_test = train_test_split(\n",
    "    X, y_binary, y_ordinal, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale the input features.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cec614f-c793-48e9-b48c-d4f80cde3662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 2. PyTorch Dataset and DataLoader\n",
    "#########################################\n",
    "\n",
    "class PainDataset(Dataset):\n",
    "    def __init__(self, X, y_binary, y_ordinal):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y_binary = torch.tensor(y_binary, dtype=torch.float32)\n",
    "        self.y_ordinal = torch.tensor(y_ordinal, dtype=torch.long)  # shape: (n_samples, num_ordinal)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y_binary[idx], self.y_ordinal[idx]\n",
    "\n",
    "# Create dataset instances.\n",
    "train_dataset = PainDataset(X_train, yb_train, yo_train)\n",
    "test_dataset  = PainDataset(X_test, yb_test, yo_test)\n",
    "\n",
    "# Create DataLoaders.\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ef53db-4969-4134-9957-e51075e1008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 3. Define the Multi–Task PyTorch Model\n",
    "#########################################\n",
    "\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_binary, num_ordinal, num_ordinal_classes=6):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        # Shared layers.\n",
    "        self.shared_fc1 = nn.Linear(input_dim, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.shared_fc2 = nn.Linear(64, 32)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        \n",
    "        # Binary head: outputs logits for each binary target.\n",
    "        self.binary_out = nn.Linear(32, num_binary)\n",
    "        \n",
    "        # Ordinal heads using CORAL: For K ordinal classes, output K-1 logits.\n",
    "        # Each head outputs (num_ordinal_classes-1) logits.\n",
    "        self.num_thresholds = num_ordinal_classes - 1\n",
    "        self.ordinal_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(32, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.1),\n",
    "                nn.Linear(16, self.num_thresholds)\n",
    "            ) for _ in range(num_ordinal)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Shared trunk.\n",
    "        x = F.relu(self.shared_fc1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.shared_fc2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Binary outputs (logits; later passed to BCEWithLogitsLoss).\n",
    "        binary_logits = self.binary_out(x)\n",
    "        \n",
    "        # Ordinal outputs: one tensor per ordinal target (each of shape [batch_size, num_thresholds]).\n",
    "        ordinal_logits = [head(x) for head in self.ordinal_heads]\n",
    "        return binary_logits, ordinal_logits\n",
    "\n",
    "# Instantiate the model.\n",
    "input_dim = 7  # number of input features\n",
    "num_binary = len(binary_target_cols)\n",
    "num_ordinal = len(ordinal_target_cols)\n",
    "num_ordinal_classes = 6  # e.g., pain levels 0-5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiTaskModel(input_dim, num_binary, num_ordinal, num_ordinal_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e22c71e-14f4-44fc-b3e3-9a0e894ffb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# 4. Training Setup\n",
    "#########################################\n",
    "\n",
    "# Define the loss for binary targets.\n",
    "criterion_binary = nn.BCEWithLogitsLoss()  # for binary targets\n",
    "\n",
    "# Define the custom CORAL loss for ordinal targets.\n",
    "def coral_loss(logits, labels):\n",
    "    \"\"\"\n",
    "    logits: tensor of shape (batch_size, K-1)\n",
    "    labels: tensor of shape (batch_size,), with integer class labels in {0,1,...,K-1}\n",
    "    \"\"\"\n",
    "    # Create binary labels for each threshold: for threshold k, target is 1 if label > k.\n",
    "    batch_size, num_thresholds = logits.size()\n",
    "    # Expand thresholds [0, 1, ..., num_thresholds-1] to match batch_size.\n",
    "    thresholds = torch.arange(num_thresholds, device=labels.device).unsqueeze(0).expand(batch_size, -1)\n",
    "    # Create binary target: 1 if label > threshold, else 0.\n",
    "    target = (labels.unsqueeze(1) > thresholds).float()\n",
    "    \n",
    "    # Compute binary cross entropy loss for each threshold.\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, target)\n",
    "    return loss\n",
    "\n",
    "# Optionally, set weights for each loss term (adjust as needed).\n",
    "loss_weight_binary = 1.0\n",
    "loss_weight_ordinal = 1.0\n",
    "\n",
    "# Use the Adam optimizer.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Set up a learning rate scheduler (for example, ReduceLROnPlateau).\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "                                                       factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "num_epochs = 50  # adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d74e6513-7987-4fc5-a5ef-7dc392cca180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Training Loss: 13.0068\n",
      "Epoch 2/50, Training Loss: 12.0387\n",
      "Epoch 3/50, Training Loss: 11.2948\n",
      "Epoch 4/50, Training Loss: 10.9307\n",
      "Epoch 5/50, Training Loss: 10.7485\n",
      "Epoch 6/50, Training Loss: 10.6838\n",
      "Epoch 7/50, Training Loss: 10.6127\n",
      "Epoch 8/50, Training Loss: 10.5549\n",
      "Epoch 9/50, Training Loss: 10.5380\n",
      "Epoch 10/50, Training Loss: 10.4907\n",
      "Epoch 11/50, Training Loss: 10.4840\n",
      "Epoch 12/50, Training Loss: 10.4587\n",
      "Epoch 13/50, Training Loss: 10.4490\n",
      "Epoch 14/50, Training Loss: 10.4617\n",
      "Epoch 15/50, Training Loss: 10.4298\n",
      "Epoch 16/50, Training Loss: 10.4130\n",
      "Epoch 17/50, Training Loss: 10.3860\n",
      "Epoch 18/50, Training Loss: 10.3960\n",
      "Epoch 19/50, Training Loss: 10.3983\n",
      "Epoch 20/50, Training Loss: 10.3817\n",
      "Epoch 21/50, Training Loss: 10.3789\n",
      "Epoch 22/50, Training Loss: 10.3697\n",
      "Epoch 23/50, Training Loss: 10.3671\n",
      "Epoch 24/50, Training Loss: 10.3755\n",
      "Epoch 25/50, Training Loss: 10.3419\n",
      "Epoch 26/50, Training Loss: 10.3507\n",
      "Epoch 27/50, Training Loss: 10.3360\n",
      "Epoch 28/50, Training Loss: 10.3377\n",
      "Epoch 29/50, Training Loss: 10.3044\n",
      "Epoch 30/50, Training Loss: 10.2910\n",
      "Epoch 31/50, Training Loss: 10.3343\n",
      "Epoch 32/50, Training Loss: 10.2971\n",
      "Epoch 33/50, Training Loss: 10.2986\n",
      "Epoch 34/50, Training Loss: 10.2920\n",
      "Epoch 35/50, Training Loss: 10.2901\n",
      "Epoch 36/50, Training Loss: 10.2739\n",
      "Epoch 37/50, Training Loss: 10.2549\n",
      "Epoch 38/50, Training Loss: 10.2521\n",
      "Epoch 39/50, Training Loss: 10.2670\n",
      "Epoch 40/50, Training Loss: 10.2682\n",
      "Epoch 41/50, Training Loss: 10.2426\n",
      "Epoch 42/50, Training Loss: 10.2380\n",
      "Epoch 43/50, Training Loss: 10.2646\n",
      "Epoch 44/50, Training Loss: 10.2255\n",
      "Epoch 45/50, Training Loss: 10.1983\n",
      "Epoch 46/50, Training Loss: 10.2246\n",
      "Epoch 47/50, Training Loss: 10.2161\n",
      "Epoch 48/50, Training Loss: 10.2210\n",
      "Epoch 49/50, Training Loss: 10.2133\n",
      "Epoch 50/50, Training Loss: 10.2266\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# 5. Training Loop\n",
    "#########################################\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for X_batch, yb_batch, yo_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        yb_batch = yb_batch.to(device)\n",
    "        yo_batch = yo_batch.to(device)  # shape: [batch_size, num_ordinal]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        binary_logits, ordinal_logits_list = model(X_batch)\n",
    "        \n",
    "        # Compute binary loss.\n",
    "        loss_binary = criterion_binary(binary_logits, yb_batch)\n",
    "        \n",
    "        # Compute ordinal loss using the custom CORAL loss for each ordinal target.\n",
    "        loss_ordinal = 0.0\n",
    "        # For each ordinal target head, compute its CORAL loss.\n",
    "        for i, ordinal_logits in enumerate(ordinal_logits_list):\n",
    "            # yo_batch[:, i] has class labels in {0,...,K-1}\n",
    "            loss_ordinal += coral_loss(ordinal_logits, yo_batch[:, i])\n",
    "        \n",
    "        # Total loss: weighted sum of both components.\n",
    "        loss = loss_weight_binary * loss_binary + loss_weight_ordinal * loss_ordinal\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * X_batch.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Step the scheduler based on the average loss.\n",
    "    scheduler.step(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8895152-c910-4f5f-b845-2bbc412fab39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary predictions (first 5):\n",
      "[[0.38379854 0.40166175 0.33546326 0.3647682  0.18747738 0.19689755\n",
      "  0.15379342 0.20028712 0.07101373 0.10339792 0.21425523 0.27681246\n",
      "  0.1677659  0.22043556 0.14158237 0.1467198  0.06142606 0.07107121]\n",
      " [0.49840266 0.44312155 0.39570817 0.42525753 0.25400436 0.24262118\n",
      "  0.24148947 0.31179896 0.14494485 0.21396242 0.34880567 0.40847367\n",
      "  0.24583411 0.34780803 0.2582178  0.32210392 0.11206195 0.11801917]\n",
      " [0.41499674 0.40447053 0.33111814 0.37698865 0.21661083 0.21829653\n",
      "  0.12861454 0.1824023  0.11278104 0.13221511 0.21244527 0.2155318\n",
      "  0.14272492 0.19313501 0.1321195  0.13210255 0.06439297 0.12196535]\n",
      " [0.36432073 0.38618973 0.2643989  0.3047712  0.22311851 0.25332028\n",
      "  0.19281267 0.23335063 0.16253036 0.16305634 0.25093216 0.28314835\n",
      "  0.15621722 0.15561493 0.18524674 0.182464   0.09820769 0.14699021]\n",
      " [0.3645084  0.2619948  0.31710893 0.28480968 0.28303197 0.23915073\n",
      "  0.15096016 0.18667065 0.10777742 0.11775968 0.2737351  0.23522149\n",
      "  0.18061462 0.21345006 0.20311585 0.1888102  0.06603661 0.09645585]]\n",
      "Ordinal predictions (first ordinal target, first 5):\n",
      "[1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# 7. Inference Example\n",
    "#########################################\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Assume X_new is a numpy array of shape (n_samples, 7) (and already scaled!)\n",
    "    # For demonstration, we use X_test.\n",
    "    X_new = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    binary_logits, ordinal_logits_list = model(X_new)\n",
    "    \n",
    "    # For binary outputs: apply sigmoid to get probabilities.\n",
    "    binary_preds = torch.sigmoid(binary_logits)\n",
    "    \n",
    "    # For ordinal outputs using CORAL: count how many thresholds are passed.\n",
    "    ordinal_preds = []\n",
    "    for logits in ordinal_logits_list:\n",
    "        # Compute probabilities for each threshold.\n",
    "        prob_thresholds = torch.sigmoid(logits)\n",
    "        # For each instance, count thresholds with probability > 0.5.\n",
    "        # This count gives the predicted class (in {0,...,K-1}).\n",
    "        pred_class = (prob_thresholds > 0.5).sum(dim=1)\n",
    "        # If you need to convert to a different scale (e.g., 1–6 instead of 0–5), add 1.\n",
    "        ordinal_preds.append(pred_class.cpu().numpy() + 1)\n",
    "    \n",
    "    # For example, print first 5 predictions.\n",
    "    print(\"Binary predictions (first 5):\")\n",
    "    print(binary_preds[:5].cpu().numpy())\n",
    "    print(\"Ordinal predictions (first ordinal target, first 5):\")\n",
    "    print(ordinal_preds[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c986d8c8-4ab1-448c-a6b2-fd1bdeac8e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary predictions (first 5):\n",
      "[[0.38379854 0.40166175 0.33546326 0.3647682  0.18747738 0.19689755\n",
      "  0.15379342 0.20028712 0.07101373 0.10339792 0.21425523 0.27681246\n",
      "  0.1677659  0.22043556 0.14158237 0.1467198  0.06142606 0.07107121]\n",
      " [0.49840266 0.44312155 0.39570817 0.42525753 0.25400436 0.24262118\n",
      "  0.24148947 0.31179896 0.14494485 0.21396242 0.34880567 0.40847367\n",
      "  0.24583411 0.34780803 0.2582178  0.32210392 0.11206195 0.11801917]\n",
      " [0.41499674 0.40447053 0.33111814 0.37698865 0.21661083 0.21829653\n",
      "  0.12861454 0.1824023  0.11278104 0.13221511 0.21244527 0.2155318\n",
      "  0.14272492 0.19313501 0.1321195  0.13210255 0.06439297 0.12196535]\n",
      " [0.36432073 0.38618973 0.2643989  0.3047712  0.22311851 0.25332028\n",
      "  0.19281267 0.23335063 0.16253036 0.16305634 0.25093216 0.28314835\n",
      "  0.15621722 0.15561493 0.18524674 0.182464   0.09820769 0.14699021]\n",
      " [0.3645084  0.2619948  0.31710893 0.28480968 0.28303197 0.23915073\n",
      "  0.15096016 0.18667065 0.10777742 0.11775968 0.2737351  0.23522149\n",
      "  0.18061462 0.21345006 0.20311585 0.1888102  0.06603661 0.09645585]]\n",
      "Ordinal predictions (first ordinal target, first 5):\n",
      "[1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# 7. Inference Example\n",
    "#########################################\n",
    "\n",
    "# To make predictions on new data:\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Assume X_new is a numpy array of shape (n_samples, 7) (and already scaled!)\n",
    "    # For demonstration, we use X_test.\n",
    "    X_new = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    binary_logits, ordinal_logits_list = model(X_new)\n",
    "    \n",
    "    # For binary outputs: apply sigmoid to get probabilities.\n",
    "    binary_preds = torch.sigmoid(binary_logits)\n",
    "    # For ordinal outputs: take the argmax to get the predicted class (0-4).\n",
    "    ordinal_preds = [torch.argmax(logits, dim=1) for logits in ordinal_logits_list]\n",
    "    \n",
    "    # If needed, convert ordinal_preds back to the original 1–5 scale:\n",
    "    ordinal_preds = [preds.cpu().numpy() + 1 for preds in ordinal_preds]\n",
    "    \n",
    "    # For example, print first 5 predictions.\n",
    "    print(\"Binary predictions (first 5):\")\n",
    "    print(binary_preds[:5].cpu().numpy())\n",
    "    print(\"Ordinal predictions (first ordinal target, first 5):\")\n",
    "    print(ordinal_preds[0][:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
